{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from meteostat import Point, Daily, Hourly, Stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 999)\n",
    "pd.set_option('display.max_rows', 999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"C:/Users/cmgas/Downloads/archive (2)/US_Accidents_Dec21_updated.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute the wind chill column\n",
    "df['Wind_Chill(F)'] = df['Wind_Chill(F)'].fillna(df['Temperature(F)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Start_Time'] = pd.to_datetime(df['Start_Time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impute the precipitation column\n",
    "\n",
    "#define a function to calculate the season\n",
    "def get_season(month, day):\n",
    "    if (month >= 3 and month <= 5) or (month == 2 and day >= 29):\n",
    "        return 'spring'\n",
    "    elif month >= 6 and month <= 8:\n",
    "        return 'summer'\n",
    "    elif month >= 9 and month <= 11:\n",
    "        return 'fall'\n",
    "    else:\n",
    "        return 'winter'\n",
    "\n",
    "# Apply get_season function to create new column\n",
    "df['season'] = df['Start_Time'].apply(lambda x: get_season(x.month, x.day))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average precipitation when it is precipitating in a given state for a given season\n",
    "\n",
    "#define a function to calculate seasonal average precipitation\n",
    "def seasonal_avg_precip(group):\n",
    "    # Filter for non-zero precipitation\n",
    "    group = group[group['Precipitation(in)'] != 0]\n",
    "    # Calculate mean precipitation\n",
    "    avg_precip = group['Precipitation(in)'].mean()\n",
    "    return avg_precip\n",
    "\n",
    "#group the dataframe by state and season, and calculate seasonal average precipitation\n",
    "seasonal_avg = df.groupby(['State', 'season']).apply(seasonal_avg_precip).reset_index(name='Seasonal_Avg_Precip')\n",
    "\n",
    "seasonal_avg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, seasonal_avg, on=['State', 'season'], how='left')\n",
    "\n",
    "weather_not_null = df[df['Weather_Condition'].notnull()]\n",
    "\n",
    "# define the list of keywords\n",
    "keywords = ['Sleet', 'Rain', 'Snow', 'Drizzle', 'Wintry Mix', 'Ice Pellets', 'Hail', 'Showers', 'Squalls']\n",
    "\n",
    "# create a boolean mask for rows with null precipitation and keywords in weather condition\n",
    "mask_keywords = weather_not_null['Precipitation(in)'].isnull() & weather_not_null['Weather_Condition'].str.contains('|'.join(keywords))\n",
    "\n",
    "# impute seasonal average precipitation values where the keyword mask is True\n",
    "weather_not_null.loc[mask_keywords, 'Precipitation(in)'] = weather_not_null['Seasonal_Avg_Precip']\n",
    "\n",
    "# create a boolean mask for rows with null precipitation and no keywords in weather condition\n",
    "mask_no_keywords = weather_not_null['Precipitation(in)'].isnull() & (~weather_not_null['Weather_Condition'].str.contains('|'.join(keywords)))\n",
    "\n",
    "# impute 0 values where the no keyword mask is True\n",
    "weather_not_null.loc[mask_no_keywords, 'Precipitation(in)'] = 0\n",
    "\n",
    "weather_not_null['Precipitation(in)'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(weather_not_null[['Precipitation(in)']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use meteostat to try to impute more missing values\n",
    "\n",
    "#get hourly weather data from meteostat using x-y coordinates\n",
    "def get_hourly_weather(latitude, longitude, timestamp):\n",
    "    # Find the closest weather station to the location\n",
    "    stations = Stations()\n",
    "    station = stations.nearby(latitude, longitude).fetch(1)\n",
    "\n",
    "    #check if station was found\n",
    "    if not station.empty:\n",
    "        station_id = station.index[0]\n",
    "\n",
    "        #extract the hour from timestamp\n",
    "        hour = timestamp.hour\n",
    "\n",
    "        #calculate start and end time for hourly data with the specific hour\n",
    "        start_time = timestamp.replace(hour=hour) - timedelta(hours=1)\n",
    "        end_time = timestamp.replace(hour=hour) + timedelta(hours=1)\n",
    "\n",
    "        # Fetch hourly data for the location and time\n",
    "        hourly_data = Hourly(station_id, start_time, end_time)\n",
    "        hourly_data = hourly_data.fetch()\n",
    "\n",
    "        hourly_data.index = pd.to_datetime(hourly_data.index)\n",
    "\n",
    "        # Filter hourly data to only include data for the specified hour\n",
    "        hourly_data = hourly_data[hourly_data.index.hour == hour]\n",
    "\n",
    "        #convert temperature from C to F\n",
    "        hourly_data['temp'] = (hourly_data['temp'] * 9/5) + 32\n",
    "\n",
    "        #convert pressure from hPA to inches\n",
    "        hourly_data['pres'] = hourly_data['pres'] * 0.02953\n",
    "\n",
    "        #convert precipitation from mm to inches\n",
    "        hourly_data['prcp'] = hourly_data['prcp'] / 25.4 \n",
    "\n",
    "        #convert wind speed from km/hr to mi/hr\n",
    "        hourly_data['wspd'] = hourly_data['wspd'] * 0.621371\n",
    "\n",
    "        return hourly_data\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the function\n",
    "test_data = {'Latitude': [39.865420],\n",
    "             'Longitude': [-84.062800],\n",
    "             'Timestamp': [datetime(2016, 2, 8, 5, 56, 20)]}\n",
    "test_df = pd.DataFrame(test_data)\n",
    "\n",
    "test_weather = get_hourly_weather(test_df['Latitude'].iloc[0], test_df['Longitude'].iloc[0], test_df['Timestamp'].iloc[0])\n",
    "print(test_weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_fetch = ['rhum', 'temp', 'prcp', 'wspd', 'pres']\n",
    "column_names = ['Humidity(%)', 'Temperature(F)', 'Precipitation(in)', 'Wind_Speed(mph)', 'Pressure(in)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = df[df[column_names].isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over rows in the df that have null values in any of the columns to fetch\n",
    "counter = 0\n",
    "for index, row in subset[subset[column_names].isnull().any(axis=1)].iterrows():\n",
    "    latitude = row['Start_Lat']\n",
    "    longitude = row['Start_Lng']\n",
    "    timestamp = row['Start_Time']\n",
    "\n",
    "    try:\n",
    "      weather_data = get_hourly_weather(latitude, longitude, timestamp)\n",
    "    except AttributeError:\n",
    "      print(f\"Error: Index {index} has no attribute 'hour'\")\n",
    "      continue\n",
    "\n",
    "    if weather_data is not None:\n",
    "        for i, column in enumerate(columns_to_fetch):\n",
    "          if pd.isnull(row[column_names[i]]):\n",
    "            if not weather_data[column].empty:\n",
    "              subset.loc[index, column_names[i]] = weather_data[column].values[0]\n",
    "              print('success - weather added')\n",
    "            else:\n",
    "              continue\n",
    "    \n",
    "    counter += 1\n",
    "print(f'Total iterations: {counter}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.update(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where everything is still null\n",
    "cols_to_check = ['Wind_Speed(mph)', 'Visibility(mi)', 'Weather_Condition', 'Humidity(%)', 'Temperature(F)', 'Pressure(in)', 'Precipitation(in)']\n",
    "final_df = df.dropna(subset=cols_to_check, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test regression to impute missing weather values\n",
    "\n",
    "cols_to_check = ['Wind_Speed(mph)', 'Visibility(mi)', 'Weather_Condition', 'Humidity(%)', 'Temperature(F)', 'Wind_Chill(F)', 'Pressure(in)', 'Precipitation(in)']\n",
    "\n",
    "\n",
    "null_percent = final_df[cols_to_check].isnull().mean() * 100\n",
    "print(null_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less than 5% NAs in remaining rows - imputation via regression is valid\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try regression for wind speed as the column with the most remaining nulls\n",
    "\n",
    "df_missing = df[df['Wind_Speed(mph)'].isnull()]\n",
    "df_not_missing = df[~df['Wind_Speed(mph)'].isnull()]\n",
    "\n",
    "predictor_cols = ['Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Precipitation(in)']\n",
    "\n",
    "X = df_not_missing[predictor_cols]\n",
    "y = df_not_missing['Wind_Speed(mph)']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'tree_method': 'exact',\n",
    "    'enable_categorical': True\n",
    "}\n",
    "\n",
    "num_round = 100\n",
    "bst = xgb.train(params, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = bst.predict(dtest)\n",
    "\n",
    "# Calculate accuracy score\n",
    "from sklearn.metrics import r2_score\n",
    "accuracy = r2_score(y_test, y_pred)\n",
    "print(\"Accuracy score on test data:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#that R2 score was terrible; let's see if we can build a better regression model to impute nulls in visibility\n",
    "\n",
    "df_for_visibility = df.copy()\n",
    "df_for_visibility['Start_Time'] = pd.to_datetime(df_for_visibility['Start_Time'])\n",
    "df_for_visibility['Start_Hour'] = df_for_visibility['Start_Time'].apply(lambda x: x.hour)\n",
    "df_for_visibility['Weather_Condition'] = df_for_visibility['Weather_Condition'].fillna('')  # fill NaN values with empty string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rain_keywords = ['Rain', 'Drizzle', 'Showers', 'Squalls']\n",
    "\n",
    "# create a function to check if any keyword is present in the string\n",
    "def check_keywords(row):\n",
    "    for keyword in rain_keywords:\n",
    "        if keyword in str(row['Weather_Condition']):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# create the 'Rain' binary predictor column\n",
    "df_for_visibility['Rain'] = df_for_visibility.apply(check_keywords, axis=1)\n",
    "\n",
    "snow_keywords = ['Sleet', 'Snow', 'Wintry Mix', 'Ice Pellets', 'Hail']\n",
    "\n",
    "# create a function to check if any keyword is present in the string\n",
    "def check_keywords(row):\n",
    "    for keyword in snow_keywords:\n",
    "        if keyword in str(row['Weather_Condition']):\n",
    "            return 1\n",
    "    return 0\n",
    "\n",
    "# create the 'Snow' binary predictor column\n",
    "df_for_visibility['Snow'] = df_for_visibility.apply(check_keywords, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_missing2 = df_for_visibility[final_df['Visibility(mi)'].isnull()]\n",
    "df_not_missing2 = df_for_visibility[~final_df['Visibility(mi)'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_cols2 = ['Temperature(F)', 'Wind_Chill(F)', 'Humidity(%)', 'Pressure(in)', 'Precipitation(in)', 'Start_Hour', 'Rain', 'Snow']\n",
    "\n",
    "X1 = df_not_missing2[predictor_cols2]\n",
    "y1 = df_not_missing2['Visibility(mi)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.2, random_state=42)\n",
    "\n",
    "dtrain1 = xgb.DMatrix(X_train1, label=y_train1)\n",
    "dtest1 = xgb.DMatrix(X_test1, label=y_test1)\n",
    "\n",
    "params = {\n",
    "    'objective': 'reg:squarederror',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'tree_method': 'exact',\n",
    "}\n",
    "\n",
    "num_round = 100\n",
    "visib_model = xgb.train(params, dtrain1, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = visib_model.predict(dtest1)\n",
    "\n",
    "# Calculate accuracy score\n",
    "accuracy1 = r2_score(y_test1, y_pred1)\n",
    "print(\"Accuracy score on test data:\", accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this regression model is also terrible, so we won't impute using regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
