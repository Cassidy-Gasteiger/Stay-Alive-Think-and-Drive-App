{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accident Propensity Index Calculation v16\n",
    "\n",
    "Working with 0 and 1 values, only using 1 values for calculations, outputting both. also outputting api and api hex color codes. also outputting number of accidents, weather conditions, and times of accidents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to calculate the distance between two points\n",
    "def distance(point1, point2):\n",
    "    lat1, lon1 = point1\n",
    "    lat2, lon2 = point2\n",
    "    km_per_lat = 110.574\n",
    "    km_per_lon = 111.320\n",
    "    dx = (lon2 - lon1) * km_per_lon * math.cos((lat1 + lat2) / 2)\n",
    "    dy = (lat2 - lat1) * km_per_lat\n",
    "    return math.sqrt(dx**2 + dy**2)\n",
    "\n",
    "# function to calculate the distance between a point and a line segment\n",
    "def distance_to_segment(point, segment_start, segment_end):\n",
    "    px, py = point\n",
    "    x1, y1 = segment_start\n",
    "    x2, y2 = segment_end\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    segment_length_squared = dx*dx + dy*dy\n",
    "    if segment_length_squared == 0:\n",
    "        return distance(point, segment_start)\n",
    "    t = max(0, min(1, ((px - x1) * dx + (py - y1) * dy) / segment_length_squared))\n",
    "    x = x1 + t * dx\n",
    "    y = y1 + t * dy\n",
    "    return distance(point, (x, y))\n",
    "\n",
    "# function to find accidents on a given route within a maximum distance\n",
    "def find_accidents_on_route(start_point, end_point, all_relevant_accidents):\n",
    "    # maximal distance of accidents from route in kilometers\n",
    "    max_distance = 0.05\n",
    "    # create a mask for accidents that are within the maximum distance from the route\n",
    "    mask = all_relevant_accidents.apply(lambda row: distance_to_segment((row['Start_Lat'], row['Start_Lng']), start_point, end_point) <= max_distance, axis=1)\n",
    "\n",
    "    # return the accidents that match the mask\n",
    "    accidents = all_relevant_accidents.loc[mask]\n",
    "    return accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main function that splits route data into 5 segments and finds corresponding accidents, calculates metrics, and generates an output json file\n",
    "def find_accidents(route_data):\n",
    "    # load route data from json file\n",
    "    with open(route_data) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # create pandas DataFrame from loaded route data with columns lat, lng, assign (with the 0 or 1)\n",
    "    data_dict_list = [{\"lat\": item[0][\"lat\"], \"lng\": item[0][\"lng\"], \"assign\": item[1]} for item in json_data]\n",
    "    route_data = pd.DataFrame(data_dict_list)\n",
    "\n",
    "    # split the route DataFrame into 5 equally sized parts\n",
    "    df_list = np.array_split(route_data, 5)\n",
    "\n",
    "    # loop through the 5 route segments\n",
    "    route_dict = {}\n",
    "    accident_dict = {}\n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "        # safe each split dataframe as a new route_df_{i} dataframe\n",
    "        route_dict[f\"route_df_{i+1}\"] = df\n",
    "\n",
    "        # reduce route data to those rows that are 100m points & create a new DataFrame to store the results\n",
    "        route_data_assigned = df[df['assign'] == 1]\n",
    "        route_data_lat_lng = route_data_assigned[['lat','lng']]\n",
    "        accidents_df = pd.DataFrame()\n",
    "        \n",
    "        # loop through the pairs of subsequent coordinates per route segment\n",
    "        for j in range(len(route_data_lat_lng) - 1):\n",
    "            # get start and end point by using the subsequent coordinate pair\n",
    "            start_point = j\n",
    "            end_point = j + 1\n",
    "\n",
    "            # retrieve relevant accident data; uses the midpoint between start and end point of a coordinate pair\n",
    "            point_lat = (route_data_lat_lng.iloc[end_point]['lat'] + route_data_lat_lng.iloc[start_point]['lat']) / 2\n",
    "            point_lng = (route_data_lat_lng.iloc[end_point]['lng'] + route_data_lat_lng.iloc[start_point]['lng']) / 2\n",
    "            dataset_id = np.char.add(np.char.add(np.char.mod('%s', point_lat.astype(str)[:4]), '_'), point_lng.astype(str)[:5])\n",
    "            # loads file only if it exists (there might be route parts where no accident file exists as there are no accidents (i.e., on non-highway routes))\n",
    "            filename = f'data/ga_accidents_{dataset_id}.csv'\n",
    "            if os.path.isfile(filename):\n",
    "                all_relevant_accidents = pd.read_csv(filename)\n",
    "                # call the accident-retrieving function and append the results to the segment-specific accidents DataFrame\n",
    "                accidents_df = pd.concat([accidents_df, find_accidents_on_route(route_data_lat_lng.iloc[start_point], route_data_lat_lng.iloc[end_point], all_relevant_accidents)], ignore_index=True)\n",
    "        \n",
    "        # drop duplicate rows from the accidents DataFrame; as we're searching for accidents around each segment within 50 meters, there could be duplicates in the accidents set\n",
    "        accidents_df.drop_duplicates(inplace=True)\n",
    "        \n",
    "        # add segment-specific accident dataframe to the accident dictionary & assign a name that reflects the segment number\n",
    "        accident_dict[f\"accidents_df_{i+1}\"] = accidents_df\n",
    "\n",
    "    # calculate api per segment\n",
    "    api_value_dict = {}\n",
    "    accidents_dfs = list(accident_dict.values())\n",
    "    for i, df in enumerate(accidents_dfs, start=1):\n",
    "        api_value = df[\"Severity\"].sum() / 6035011\n",
    "        api_value_dict[f'api_{i}'] = round(api_value, 8)\n",
    "\n",
    "    # convert api values into colors\n",
    "    api_color_dict = api_value_dict.copy()\n",
    "    min_api_value = min(api_color_dict.values())\n",
    "    max_api_value = max(api_color_dict.values())\n",
    "    for key in api_color_dict:\n",
    "        api_color_dict[key] = (api_value_dict[key] - min_api_value) / (max_api_value - min_api_value)\n",
    "    def get_hex_color(value):\n",
    "        # convert a normalized value to a hex color code representing a gradient from green to red.\n",
    "        r = int(255 * value)\n",
    "        g = int(255 * (1 - value))\n",
    "        b = 0\n",
    "        return f'{r:02x}{g:02x}{b:02x}'\n",
    "    for key in api_color_dict:\n",
    "        api_color_dict[key] = get_hex_color(api_color_dict[key])\n",
    "\n",
    "    # number of accidents per segment\n",
    "    num_accidents_dict = {}\n",
    "    accidents_dfs = list(accident_dict.values())\n",
    "    for i, df in enumerate(accidents_dfs, start=1):\n",
    "        num_accidents = df.shape[0]\n",
    "        num_accidents_dict[f'acci_{i}'] = num_accidents\n",
    "\n",
    "    # time of the day of accidents per segment\n",
    "    accident_time_dict = {}\n",
    "    accidents_dfs = list(accident_dict.values())\n",
    "    for i, df in enumerate(accidents_dfs, start=1):\n",
    "        df['Start_Time'] = pd.to_datetime(df['Start_Time'])\n",
    "        hour_counts = df['Start_Time'].dt.hour.value_counts().sort_index().to_dict()\n",
    "        for hour in range(24):\n",
    "            if hour not in hour_counts:\n",
    "                hour_counts[hour] = 0\n",
    "        hour_counts = dict(sorted(hour_counts.items()))\n",
    "        accident_time_dict[f'time_{i}'] = hour_counts\n",
    "\n",
    "    # top 5 weather conditions per segment\n",
    "    weather_condition_dict = {}\n",
    "    accidents_dfs = list(accident_dict.values())\n",
    "    top_n = 5 # number of top weather conditions to include in the dictionary\n",
    "    for i, df in enumerate(accidents_dfs, start=1):\n",
    "        weather_counts = df['Weather_Condition'].value_counts().head(top_n).to_dict()\n",
    "        weather_condition_dict[f'weather_{i}'] = weather_counts\n",
    "\n",
    "    # create a dictionary to store the JSON data & loop over the segments and add the API and route data to the JSON dictionary\n",
    "    json_dict = {}\n",
    "    route_dfs = list(route_dict.values())   \n",
    "    for i in range(5):\n",
    "        segment_name = f\"segment_{i+1}\"\n",
    "        json_dict[segment_name] = {}\n",
    "        json_dict[segment_name][\"api_value\"] = api_value_dict[f\"api_{i+1}\"]\n",
    "        json_dict[segment_name][\"api_color\"] = api_color_dict[f\"api_{i+1}\"]\n",
    "        json_dict[segment_name][\"num_accidents\"] = num_accidents_dict[f\"acci_{i+1}\"]\n",
    "        json_dict[segment_name][\"accident_time\"] = accident_time_dict[f\"time_{i+1}\"]\n",
    "        json_dict[segment_name][\"weather_condition\"] = weather_condition_dict[f\"weather_{i+1}\"]\n",
    "        json_dict[segment_name][\"route\"] = route_dfs[i][[\"lat\", \"lng\"]].to_dict(orient=\"records\")\n",
    "\n",
    "    # export the JSON file\n",
    "    with open(\"backend_output.json\", \"w\") as f:\n",
    "        json.dump(json_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the main function with the route data\n",
    "find_accidents('athens_GA_path.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
