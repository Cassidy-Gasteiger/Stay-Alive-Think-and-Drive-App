{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accident Propensity Index Calculation v09"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to calculate distances and find accidents on route - run once at start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the distance between two points\n",
    "def distance(point1, point2):\n",
    "    lat1, lon1 = point1\n",
    "    lat2, lon2 = point2\n",
    "    km_per_lat = 110.574 # km per degree latitude\n",
    "    km_per_lon = 111.320 # km per degree longitude at the equator\n",
    "    dx = (lon2 - lon1) * km_per_lon * math.cos((lat1 + lat2) / 2)\n",
    "    dy = (lat2 - lat1) * km_per_lat\n",
    "    return math.sqrt(dx**2 + dy**2)\n",
    "\n",
    "# Define a function to calculate the distance between a point and a line segment\n",
    "def distance_to_segment(point, segment_start, segment_end):\n",
    "    px, py = point\n",
    "    x1, y1 = segment_start\n",
    "    x2, y2 = segment_end\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    segment_length_squared = dx*dx + dy*dy\n",
    "    if segment_length_squared == 0:\n",
    "        return distance(point, segment_start)\n",
    "    t = max(0, min(1, ((px - x1) * dx + (py - y1) * dy) / segment_length_squared))\n",
    "    x = x1 + t * dx\n",
    "    y = y1 + t * dy\n",
    "    return distance(point, (x, y))\n",
    "\n",
    "# Define a function to find accidents on a given route within a maximum distance\n",
    "def find_accidents_on_route(start_point, end_point, all_relevant_accidents):\n",
    "    # Maximal distance of accidents from route in kilometers\n",
    "    max_distance = 0.05\n",
    "    # Create a mask for accidents that are within the maximum distance from the route\n",
    "    mask = all_relevant_accidents.apply(lambda row: distance_to_segment((row['Start_Lat'], row['Start_Lng']), start_point, end_point) <= max_distance, axis=1)\n",
    "\n",
    "    # Return the accidents that match the mask\n",
    "    accidents = all_relevant_accidents.loc[mask]\n",
    "    return accidents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find accidents on route - run every time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accidents():\n",
    "    # load route data from json file\n",
    "    with open('route_data.json') as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # create DataFrame from loaded data\n",
    "    route_data = pd.DataFrame(json_data)\n",
    "\n",
    "    # load relevant accident data csv files and concatenate\n",
    "    unique_values = route_data['route_lat'].astype(str).str[:2].unique().tolist()\n",
    "    dfs = []\n",
    "    for val in unique_values:\n",
    "        file_path = f'new_data/accident_data_{val}.csv'\n",
    "        df = pd.read_csv(file_path)\n",
    "        dfs.append(df)\n",
    "    all_relevant_accidents = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # split the route DataFrame into 5 equally sized parts\n",
    "    df_list = np.array_split(route_data, 5)\n",
    "\n",
    "    # loop through the route DataFrames\n",
    "    for i, df in enumerate(df_list):\n",
    "        # Safe each split dataframe as a new route_df_{i} dataframe\n",
    "        globals()[f\"route_df_{i+1}\"] = df\n",
    "        # Create a new DataFrame to store the results\n",
    "        accidents_df = pd.DataFrame()\n",
    "        # Loop through the pairs of subsequent coordinates\n",
    "        for j in range(len(df) - 1):\n",
    "            start_point = j\n",
    "            end_point = j + 1\n",
    "            # Call the function and append the results to the accidents DataFrame\n",
    "            accidents_df = accidents_df.append(find_accidents_on_route(df.iloc[start_point], df.iloc[end_point], all_relevant_accidents), ignore_index=True)\n",
    "        # Drop duplicate rows from the accidents DataFrame\n",
    "        accidents_df.drop_duplicates(inplace=True)\n",
    "        \n",
    "        # Assign a name to the accidents DataFrame based on the index of the original DataFrame\n",
    "        df_index = i+1\n",
    "        globals()[f'accidents_df_{df_index}'] = accidents_df\n",
    "\n",
    "    # create a list of dataframes for the API calculation\n",
    "    accidents_dfs = [accidents_df_1, accidents_df_2, accidents_df_3, accidents_df_4, accidents_df_5]\n",
    "    api_dict = {}\n",
    "\n",
    "    # loop through the list of dataframes and join each one with the all_accidents dataframe\n",
    "    for i, df in enumerate(accidents_dfs, start=1):\n",
    "        api = df[\"Severity\"].sum() / 6035011\n",
    "        api_dict[f'api_{i}'] = round(api, 8)\n",
    "\n",
    "\n",
    "    # List of the segment dataframes, each containing the coordinates that are assigned to the respective segment\n",
    "    route_dfs = [route_df_1, route_df_2, route_df_3, route_df_4, route_df_5]\n",
    "\n",
    "    # Create a dictionary to store the JSON data\n",
    "    json_dict = {}\n",
    "\n",
    "    # Loop over the segments and add the API and route data to the JSON dictionary\n",
    "    for i in range(5):\n",
    "        segment_name = f\"segment_{i+1}\"\n",
    "        json_dict[segment_name] = {}\n",
    "        json_dict[segment_name][\"api\"] = api_dict[f\"api_{i+1}\"]\n",
    "        json_dict[segment_name][\"route\"] = route_dfs[i].to_dict(orient=\"records\")\n",
    "\n",
    "    # Write the JSON data to a file\n",
    "    with open(\"backend_output.json\", \"w\") as f:\n",
    "        json.dump(json_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2z/5xl96y_10clcjhbp86qg3fyr0000gn/T/ipykernel_60102/1918912227.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  accidents_df = accidents_df.append(find_accidents_on_route(df.iloc[start_point], df.iloc[end_point], all_relevant_accidents), ignore_index=True)\n",
      "/var/folders/2z/5xl96y_10clcjhbp86qg3fyr0000gn/T/ipykernel_60102/1918912227.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  accidents_df = accidents_df.append(find_accidents_on_route(df.iloc[start_point], df.iloc[end_point], all_relevant_accidents), ignore_index=True)\n",
      "/var/folders/2z/5xl96y_10clcjhbp86qg3fyr0000gn/T/ipykernel_60102/1918912227.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  accidents_df = accidents_df.append(find_accidents_on_route(df.iloc[start_point], df.iloc[end_point], all_relevant_accidents), ignore_index=True)\n",
      "/var/folders/2z/5xl96y_10clcjhbp86qg3fyr0000gn/T/ipykernel_60102/1918912227.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  accidents_df = accidents_df.append(find_accidents_on_route(df.iloc[start_point], df.iloc[end_point], all_relevant_accidents), ignore_index=True)\n",
      "/var/folders/2z/5xl96y_10clcjhbp86qg3fyr0000gn/T/ipykernel_60102/1918912227.py:32: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  accidents_df = accidents_df.append(find_accidents_on_route(df.iloc[start_point], df.iloc[end_point], all_relevant_accidents), ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "find_accidents()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
