{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accident Propensity Index Calculation v15\n",
    "\n",
    "Working with 0 and 1 values, only using 1 values for calculations, outputting both. also outputting hex color codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate the distance between two points\n",
    "def distance(point1, point2):\n",
    "    lat1, lon1 = point1\n",
    "    lat2, lon2 = point2\n",
    "    km_per_lat = 110.574\n",
    "    km_per_lon = 111.320\n",
    "    dx = (lon2 - lon1) * km_per_lon * math.cos((lat1 + lat2) / 2)\n",
    "    dy = (lat2 - lat1) * km_per_lat\n",
    "    return math.sqrt(dx**2 + dy**2)\n",
    "\n",
    "# Define a function to calculate the distance between a point and a line segment\n",
    "def distance_to_segment(point, segment_start, segment_end):\n",
    "    px, py = point\n",
    "    x1, y1 = segment_start\n",
    "    x2, y2 = segment_end\n",
    "    dx, dy = x2 - x1, y2 - y1\n",
    "    segment_length_squared = dx*dx + dy*dy\n",
    "    if segment_length_squared == 0:\n",
    "        return distance(point, segment_start)\n",
    "    t = max(0, min(1, ((px - x1) * dx + (py - y1) * dy) / segment_length_squared))\n",
    "    x = x1 + t * dx\n",
    "    y = y1 + t * dy\n",
    "    return distance(point, (x, y))\n",
    "\n",
    "# Define a function to find accidents on a given route within a maximum distance\n",
    "def find_accidents_on_route(start_point, end_point, all_relevant_accidents):\n",
    "    # Maximal distance of accidents from route in kilometers\n",
    "    max_distance = 0.05\n",
    "    # Create a mask for accidents that are within the maximum distance from the route\n",
    "    mask = all_relevant_accidents.apply(lambda row: distance_to_segment((row['Start_Lat'], row['Start_Lng']), start_point, end_point) <= max_distance, axis=1)\n",
    "\n",
    "    # Return the accidents that match the mask\n",
    "    accidents = all_relevant_accidents.loc[mask]\n",
    "    return accidents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accidents(route_data):\n",
    "    # load route data from json file\n",
    "    with open(route_data) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    # create DataFrame from loaded data & create DataFrame from list of dictionaries\n",
    "    data_dict_list = [{\"lat\": item[0][\"lat\"], \"lng\": item[0][\"lng\"], \"assign\": item[1]} for item in json_data]\n",
    "    route_data = pd.DataFrame(data_dict_list)\n",
    "\n",
    "    # split the route DataFrame into 5 equally sized parts\n",
    "    df_list = np.array_split(route_data, 5)\n",
    "\n",
    "    # loop through the route DataFrames\n",
    "    route_dict = {}\n",
    "    accident_dict = {}\n",
    "    for i, df in enumerate(df_list):\n",
    "        \n",
    "\n",
    "        \n",
    "        # Safe each split dataframe as a new route_df_{i} dataframe\n",
    "        route_dict[f\"route_df_{i+1}\"] = df\n",
    "\n",
    "        # reduce data to needed columns\n",
    "        route_data_assigned = df[df['assign'] == 1]\n",
    "        route_data_lat_lng = route_data_assigned[['lat','lng']]\n",
    "\n",
    "\n",
    "        # Create a new DataFrame to store the results\n",
    "        accidents_df = pd.DataFrame()\n",
    "        \n",
    "        # Loop through the pairs of subsequent coordinates\n",
    "        for j in range(len(route_data_lat_lng) - 1):\n",
    "            start_point = j\n",
    "            end_point = j + 1\n",
    "\n",
    "            # Get relevant data\n",
    "            point_lat = (route_data_lat_lng.iloc[end_point]['lat'] + route_data_lat_lng.iloc[start_point]['lat']) / 2\n",
    "            point_lng = (route_data_lat_lng.iloc[end_point]['lng'] + route_data_lat_lng.iloc[start_point]['lng']) / 2\n",
    "            dataset_id = np.char.add(np.char.add(np.char.mod('%s', point_lat.astype(str)[:4]), '_'), point_lng.astype(str)[:5])\n",
    "\n",
    "            filename = f'data/ga_accidents_{dataset_id}.csv'\n",
    "            if os.path.isfile(filename):\n",
    "                all_relevant_accidents = pd.read_csv(filename)\n",
    "                # Call the function and append the results to the accidents DataFrame\n",
    "                accidents_df = pd.concat([accidents_df, find_accidents_on_route(route_data_lat_lng.iloc[start_point], route_data_lat_lng.iloc[end_point], all_relevant_accidents)], ignore_index=True)\n",
    "            \n",
    "        # Drop duplicate rows from the accidents DataFrame\n",
    "        accidents_df.drop_duplicates(inplace=True)\n",
    "        \n",
    "        # Assign a name to the accidents DataFrame based on the index of the original DataFrame\n",
    "        accident_dict[f\"accidents_df_{i+1}\"] = accidents_df\n",
    "\n",
    "    # list of accident dataframes\n",
    "    accidents_dfs = list(accident_dict.values())\n",
    "\n",
    "    # create a list of dataframes for the API calculation & calculate api per segment\n",
    "    api_dict = {}\n",
    "    for i, df in enumerate(accidents_dfs, start=1):\n",
    "        api = df[\"Severity\"].sum() / 6035011\n",
    "        api_dict[f'api_{i}'] = round(api, 8)\n",
    "\n",
    "    # Converting API values into colors\n",
    "    min_api_value = min(api_dict.values())\n",
    "    max_api_value = max(api_dict.values())\n",
    "    for key in api_dict:\n",
    "        api_dict[key] = (api_dict[key] - min_api_value) / (max_api_value - min_api_value)\n",
    "    def get_hex_color(value):\n",
    "        # Convert a normalized value to a hex color code representing a gradient from green to red.\n",
    "        r = int(255 * value)\n",
    "        g = int(255 * (1 - value))\n",
    "        b = 0\n",
    "        return f'{r:02x}{g:02x}{b:02x}'\n",
    "    for key in api_dict:\n",
    "        api_dict[key] = get_hex_color(api_dict[key])\n",
    "\n",
    "    # List of the segment dataframes, each containing the coordinates that are assigned to the respective segment\n",
    "    route_dfs = list(route_dict.values())\n",
    "\n",
    "    # Create a dictionary to store the JSON data\n",
    "    json_dict = {}\n",
    "\n",
    "    # Loop over the segments and add the API and route data to the JSON dictionary\n",
    "    for i in range(5):\n",
    "        segment_name = f\"segment_{i+1}\"\n",
    "        json_dict[segment_name] = {}\n",
    "        json_dict[segment_name][\"api\"] = api_dict[f\"api_{i+1}\"]\n",
    "        json_dict[segment_name][\"route\"] = route_dfs[i][[\"lat\", \"lng\"]].to_dict(orient=\"records\")\n",
    "\n",
    "    # Write the JSON data to a file\n",
    "    with open(\"backend_output.json\", \"w\") as f:\n",
    "        json.dump(json_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_accidents('selection_coded_path_large_subset.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
